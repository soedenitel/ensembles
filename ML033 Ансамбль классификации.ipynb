{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b13e14",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузим данные, приведем их к числовым, заполним пропуски, нормализуем данные и оптимизируем память.\n",
    "\n",
    "Разделим выборку на обучающую/проверочную в соотношении 80/20.\n",
    "\n",
    "Сформируем параллельный ансамбль из логистической регрессии, SVM, случайного леса и LightGBM. Используем лучшие гиперпараметры, подобранные ранее. Итоговое решение рассчитаем на основании весов (вероятностей).\n",
    "\n",
    "Проведем предсказание и проверим качество через каппа-метрику.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/prudential/train.csv.gz\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/prudential-life-insurance-assessment/\n",
    "\n",
    "© ITtensive, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54855ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAIN = 11\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from etl_utils import reduce_mem_usage\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"https://video.ittensive.com/machine-learning/prudential/train.csv.gz\")\n",
    "\n",
    "data['Product_Info_2_1'] = data['Product_Info_2'].str.slice(0, 1)\n",
    "data['Product_Info_2_2'] = pd.to_numeric(data['Product_Info_2'].str.slice(1, 2))\n",
    "data = data.drop('Product_Info_2', axis='columns')\n",
    "\n",
    "onehot_df = pd.get_dummies(data['Product_Info_2_1'])\n",
    "onehot_df.columns = ['Product_Info_2_1' + column for column in onehot_df.columns]\n",
    "data = pd.merge(left=data, right=onehot_df, left_index=True, right_index=True).drop('Product_Info_2_1', axis=1).fillna(-1)\n",
    "del onehot_df\n",
    "\n",
    "data['Response'] = data['Response'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb52cc",
   "metadata": {},
   "source": [
    "### Набор столбцов для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1829c322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wt', 'Ht', 'Ins_Age', 'BMI', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', 'Medical_Keyword_1', 'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4', 'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7', 'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10', 'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13', 'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16', 'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19', 'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22', 'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25', 'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28', 'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31', 'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34', 'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37', 'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48', 'Family_Hist_1', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', 'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_15', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_24', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', 'Medical_History_31', 'Medical_History_32', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_40', 'Medical_History_41', 'Product_Info_1', 'Product_Info_3', 'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7', 'Product_Info_2_2', 'Product_Info_2_1A', 'Product_Info_2_1B', 'Product_Info_2_1C', 'Product_Info_2_1D', 'Product_Info_2_1E']\n"
     ]
    }
   ],
   "source": [
    "columns_groups = ['Insurance_History', 'InsurеdInfo', 'Medical_Keyword', 'Family_Hist', 'Medical_History', 'Product_Info']\n",
    "columns = ['Wt', 'Ht', 'Ins_Age', 'BMI']\n",
    "for cg in columns_groups:\n",
    "    columns.extend(data.columns[data.columns.str.startswith(cg)])\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e99577",
   "metadata": {},
   "source": [
    "### Нормализация данных и Разделение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede3fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 40.49 Мб (-75.1%)\n",
      "(47504, 119) (11877, 119)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "data_transformed = pd.DataFrame(scaler.fit_transform(data[columns]))\n",
    "columns_transformed = data_transformed.columns\n",
    "data_transformed['Response'] = data['Response']\n",
    "data_transformed = reduce_mem_usage(data_transformed)\n",
    "\n",
    "data_train, data_test = train_test_split(data_transformed, test_size=.2, random_state=GRAIN)\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c3b28a",
   "metadata": {},
   "source": [
    "### Построение базовых моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b687e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_train[columns_transformed]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b4b4c",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a0704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soede\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', probability=True, max_iter=10000).fit(x, data_train['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf859ab",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bed2e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logr = LogisticRegression(max_iter=1000).fit(x, data_train['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451262bc",
   "metadata": {},
   "source": [
    "Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eff418ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(\n",
    "    random_state=GRAIN,\n",
    "    n_estimators=76,\n",
    "    max_depth=17,\n",
    "    max_features=27,\n",
    "    min_samples_leaf=20\n",
    ").fit(x, data_train['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05b2f1",
   "metadata": {},
   "source": [
    "LightGBM, используем multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135be29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(\n",
    "    random_state=GRAIN, max_depth=18, min_child_samples=18, num_leaves=75, n_estimators=1000,\n",
    "    objective=\"multiclass\", num_class=8\n",
    ").fit(x, data_train['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6218423",
   "metadata": {},
   "source": [
    "### Расчет предказаний\n",
    "Кроме непосредственно значений дополнительно посчитаем вероятности совпадения с тем или иным классом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed8d2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = data_test[columns_transformed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86d7f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_svm_proba = pd.DataFrame(model_svm.predict_proba(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfc324a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_logr_proba = pd.DataFrame(model_logr.predict_proba(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "831e630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_rf_proba = pd.DataFrame(model_rf.predict_proba(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05dd74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_lgb = pd.DataFrame(model_lgb.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd713b",
   "metadata": {},
   "source": [
    "Несколько вариантов ансамблей с голосованием (выбор класса выполняется для каждого кортежа по отдельности):\n",
    "* \"Мягкое\" голосование (в том числе, с определенными весами): суммируются вероятности каждого класса среди всех оценок, выбирается наибольшее.\n",
    "* \"Жесткое\" (мажоритарное) голосование: выбирается самый популярный класс среди моделей (число моделей должно быть нечетным).\n",
    "* Отсечение: из вероятностей моделей выбирается только наиболее значимые, например, больше 0.3.\n",
    "* Экспертное голосование: вес оценки эксперта зависит от кортежа данных и самого класса (например, если определенная модель предсказывает определенный класс точнее других).\n",
    "\n",
    "Здесь используем \"мягкое\" голосование, для этого необходимо рассчитать вероятности всех класса для каждого кортежа данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55ea9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_class(x):\n",
    "    return np.argmax(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b63d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_proba = data_test_svm_proba.copy()\n",
    "for i in range(0, data_test_proba.shape[1]):\n",
    "    data_test_proba[i] *= .2\n",
    "    data_test_proba[i] += data_test_logr_proba[i]\n",
    "    data_test_proba[i] += data_test_rf_proba[i]\n",
    "    data_test_proba[i] += 50 * data_test_lgb[i]\n",
    "    \n",
    "data_test_proba['target'] = data_test_proba.apply(vote_class, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67768b39",
   "metadata": {},
   "source": [
    "### Оценка ансамбля\n",
    "Рассчитаем оценку взвешенного предсказания 4 моделей\n",
    "\n",
    "Кластеризация дает 0.192, kNN(100) - 0.3, лог. регрессия - 0.512/0.496, SVM - 0.95, реш. дерево - 0.3, случайный лес - 0.487, XGBoost - 0.534, градиентный бустинг - 0.545, LightGBM - 0.551, CatBoost - 0.543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2814b623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ансамбль классификации: 0.55\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Ансамбль классификации:\",\n",
    "    round(cohen_kappa_score(data_test_proba[\"target\"], data_test[\"Response\"], weights=\"quadratic\"), 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f156a2",
   "metadata": {},
   "source": [
    "### Матрица неточностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad5a19be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ансамбль классификации\n",
      " [[ 273  147   27   24   57  112   44   28]\n",
      " [ 204  338   24   13  101  109   35   17]\n",
      " [  14   26   61   16    1    0    0    0]\n",
      " [  36   25   52  205    0    2    0    1]\n",
      " [  94  131   10    0  570  106   10   10]\n",
      " [ 244  268   20   21  192 1215  277  164]\n",
      " [ 122  117    3    3   53  245  658  161]\n",
      " [ 251  255    5   34   90  447  538 3571]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ансамбль классификации\\n\", confusion_matrix(data_test_proba[\"target\"], data_test[\"Response\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede63a0",
   "metadata": {},
   "source": [
    "### Само-проверка\n",
    "Проверим, насколько ансамбль хорошо предсказывает обучающие данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a310d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат: 1.0\n",
      "[[ 4969     0     0     0     0     0     0     0]\n",
      " [    0  5245     0     0     0     0     0     0]\n",
      " [    0     0   811     0     0     0     0     0]\n",
      " [    0     0     0  1112     0     0     0     0]\n",
      " [    0     0     0     0  4368     0     0     0]\n",
      " [    0     0     0     0     0  8996     0     0]\n",
      " [    0     0     0     0     0     0  6463     0]\n",
      " [    0     0     0     0     0     1     2 15537]]\n"
     ]
    }
   ],
   "source": [
    "data_train_svm = pd.DataFrame(model_svm.predict_proba(x))\n",
    "data_train_logr = pd.DataFrame(model_logr.predict_proba(x))\n",
    "data_train_rf = pd.DataFrame(model_rf.predict_proba(x))\n",
    "data_train_lgb = pd.DataFrame(model_lgb.predict(x))\n",
    "\n",
    "for i in range(0, data_train_svm.shape[1]):\n",
    "    data_train_svm[i] *= .2\n",
    "    data_train_svm[i] += data_train_logr[i]\n",
    "    data_train_svm[i] += data_train_rf[i]\n",
    "    data_train_svm[i] += 50 * data_train_lgb[i]\n",
    "    \n",
    "target = data_train_svm.apply(vote_class, axis='columns')\n",
    "print(\"Результат:\", round(cohen_kappa_score(target, data_train[\"Response\"], weights=\"quadratic\"), 3))\n",
    "print(confusion_matrix(target, data_train[\"Response\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
