{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a493fb4",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузим данные, приведем их к числовым, заполним пропуски, нормализуем данные и оптимизируем память.\n",
    "\n",
    "Разделим выборку на обучающую/проверочную в соотношении 80/20.\n",
    "\n",
    "Построим последовательный ансамбль решающих деревьев, используя облегченный градиентный бустинг (LightGBM). Используем перекрестную проверку, чтобы найти наилучшие параметры ансамбля.\n",
    "\n",
    "Проведем предсказание и проверим качество через каппа-метрику.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/prudential/train.csv.gz\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/prudential-life-insurance-assessment/\n",
    "\n",
    "© ITtensive, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d43918",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAIN = 11\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from etl_utils import reduce_mem_usage\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"https://video.ittensive.com/machine-learning/prudential/train.csv.gz\")\n",
    "\n",
    "data['Product_Info_2_1'] = data['Product_Info_2'].str.slice(0, 1)\n",
    "data['Product_Info_2_2'] = pd.to_numeric(data['Product_Info_2'].str.slice(1, 2))\n",
    "data = data.drop('Product_Info_2', axis='columns')\n",
    "\n",
    "onehot_df = pd.get_dummies(data['Product_Info_2_1'])\n",
    "onehot_df.columns = ['Product_Info_2_1' + column for column in onehot_df.columns]\n",
    "data = pd.merge(left=data, right=onehot_df, left_index=True, right_index=True).drop('Product_Info_2_1', axis=1).fillna(-1)\n",
    "del onehot_df\n",
    "\n",
    "data['Response'] = data['Response'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fb3db",
   "metadata": {},
   "source": [
    "### Набор столбцов для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e02d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wt', 'Ht', 'Ins_Age', 'BMI', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', 'Medical_Keyword_1', 'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4', 'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7', 'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10', 'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13', 'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16', 'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19', 'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22', 'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25', 'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28', 'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31', 'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34', 'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37', 'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48', 'Family_Hist_1', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', 'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_15', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_24', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', 'Medical_History_31', 'Medical_History_32', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_40', 'Medical_History_41', 'Product_Info_1', 'Product_Info_3', 'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7', 'Product_Info_2_2', 'Product_Info_2_1A', 'Product_Info_2_1B', 'Product_Info_2_1C', 'Product_Info_2_1D', 'Product_Info_2_1E']\n"
     ]
    }
   ],
   "source": [
    "columns_groups = ['Insurance_History', 'InsurеdInfo', 'Medical_Keyword', 'Family_Hist', 'Medical_History', 'Product_Info']\n",
    "columns = ['Wt', 'Ht', 'Ins_Age', 'BMI']\n",
    "for cg in columns_groups:\n",
    "    columns.extend(data.columns[data.columns.str.startswith(cg)])\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b6c3a",
   "metadata": {},
   "source": [
    "### Нормализация данных и Разделение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3815030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 40.49 Мб (-75.1%)\n",
      "(47504, 119) (11877, 119)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "data_transformed = pd.DataFrame(scaler.fit_transform(data[columns]))\n",
    "columns_transformed = data_transformed.columns\n",
    "data_transformed['Response'] = data['Response']\n",
    "data_transformed = reduce_mem_usage(data_transformed)\n",
    "\n",
    "data_train, data_test = train_test_split(data_transformed, test_size=.2, random_state=GRAIN)\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5412e30",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "Основное отличие этого градиентного бустинга от предыдущих - использование сильно-разнородных (определяется разностью, гистограммой самих данных) экземпляров в выборке для формирования первоначального дерева: сначала рассматриваются все крайние, \"плохие\", случаи, а затем к ним \"достраиваются\" средние, \"хорошие\". Это позволяет еще быстрее минимизировать ошибку моделей.\n",
    "\n",
    "Из дополнительных плюсов: алгоритм запускается сразу на всех ядрах процессора, это существенно ускоряет работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b70818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMRegressor(random_state=GRAIN, max_depth=18, min_child_samples=19, num_leaves=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729086d5",
   "metadata": {},
   "source": [
    "Также возможно провести классификации множества классов через LightGBM. В этом случае модель вернет вероятности принадлежности к каждому классу, возвращенные значения нужно будет дополнительно обработать через argmax, чтобы получить единственное значение класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58fee995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = lgb.LGBMRegressor(random_state=17, max_depth=17,\\n                min_child_samples=18, num_leaves=34,\\n                objective=\"multiclass\", num_class=8)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = lgb.LGBMRegressor(random_state=17, max_depth=17,\n",
    "                min_child_samples=18, num_leaves=34,\n",
    "                objective=\"multiclass\", num_class=8)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d86988",
   "metadata": {},
   "source": [
    "Диапазон тестирования параметров модели ограничен только вычислительной мощностью. Для проверки модели имеет смысл провести индивидуальные перекрестные проверки для каждого параметра в отдельности, затем в итоговой проверке перепроверить самые лучшие найденные параметры с отклонением +/-10%.\n",
    "\n",
    "Проверку качества по каппа метрике при оптимизации выполнить не удастся из-за нецелых значений Light GBM. Гиперпараметры оптимизации:\n",
    "* max_depth - максимальная глубина деревьев,\n",
    "* num_leaves - число листьев в каждом\n",
    "* min_child_samples - минимальное число элементов выборке в листе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734ed9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'max_depth': range(16, 19),\n",
    "    'num_leaves': range(34, 37),\n",
    "    'min_child_samples': range(17, 20)\n",
    "}\n",
    "grid = GridSearchCV(model, lgb_params, cv=5, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39d91e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU times: total: 6.7 s\n",
      "Wall time: 20.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LGBMRegressor(max_depth=18, min_child_samples=19,\n",
       "                                     num_leaves=34, random_state=11),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': range(16, 19),\n",
       "                         'min_child_samples': range(17, 20),\n",
       "                         'num_leaves': range(34, 37)},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(data_train[columns_transformed], data_train['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2bafca",
   "metadata": {},
   "source": [
    "Выведем самые оптимальные параметры и построим итоговую модель, используя 1000 последовательных деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e701a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 16, 'min_child_samples': 18, 'num_leaves': 36}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "model = lgb.LGBMRegressor(\n",
    "    random_state=17,\n",
    "    max_depth=grid.best_params_['max_depth'],\n",
    "    min_child_samples=grid.best_params_['min_child_samples'],\n",
    "    num_leaves=grid.best_params_['num_leaves'],\n",
    "    n_estimators=1000,\n",
    "    objective='multiclass', num_class=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e650e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 16s\n",
      "Wall time: 17.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(max_depth=16, min_child_samples=18, n_estimators=1000,\n",
       "              num_class=8, num_leaves=36, objective='multiclass',\n",
       "              random_state=17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(data_train[columns_transformed], data_train['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7b8b9",
   "metadata": {},
   "source": [
    "### Предсказание данных и оценка модели\n",
    "LightGBM возвращает дробное значение класса, его нужно округлить.\n",
    "\n",
    "Для multiclass используем argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9256cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model(x):\n",
    "    return np.argmax(model.predict([x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c823a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM: 0.551\n"
     ]
    }
   ],
   "source": [
    "data_test['target'] = data_test[columns_transformed].apply(calculate_model, axis='columns')\n",
    "print(\"LightGBM:\", round(cohen_kappa_score(data_test[\"target\"], data_test[\"Response\"], weights=\"quadratic\"), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c3643",
   "metadata": {},
   "source": [
    "Кластеризация дает 0.192, kNN(100) - 0.3, лог. регрессия - 0.512/0.496, SVM - 0.95, реш. дерево - 0.3, случайный лес - 0.487, XGBoost - 0.534, градиентный бустинг - 0.545"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c314f",
   "metadata": {},
   "source": [
    "### Матрица неточностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e44291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      " [[ 288  164   34   32   59  128   54   36]\n",
      " [ 215  345   25    9  106  122   40   30]\n",
      " [  14   24   56   18    0    0    0    0]\n",
      " [  39   27   52  198    0    3    0    1]\n",
      " [  91  131    7    1  570  110   10   10]\n",
      " [ 244  262   20   19  189 1162  260  164]\n",
      " [ 130  121    4    7   51  270  695  197]\n",
      " [ 217  233    4   32   89  441  503 3514]]\n"
     ]
    }
   ],
   "source": [
    "print(\"LightGBM\\n\", confusion_matrix(data_test[\"target\"], data_test[\"Response\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
